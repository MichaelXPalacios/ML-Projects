# -*- coding: utf-8 -*-
"""Kfold EX and Titantic Working.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wMkj3CrLEnOPcLWT6kbD2RPW7Jy0XYT3
"""

#Importing required libraries
from sklearn.datasets import load_breast_cancer
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

#Loading the dataset
data = load_breast_cancer(as_frame = True)
df = data.frame
X = df.iloc[:,:-1]
y = df.iloc[:,-1]

#Implementing cross validation

k = 5
kf = KFold(n_splits=k, random_state=None)
model = LogisticRegression(solver= 'liblinear')

acc_score = []

for train_index , test_index in kf.split(X):
    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]
    y_train , y_test = y[train_index] , y[test_index]

    model.fit(X_train,y_train)
    pred_values = model.predict(X_test)

    acc = accuracy_score(pred_values , y_test)
    acc_score.append(acc)

avg_acc_score = sum(acc_score)/k

print('accuracy of each fold - {}'.format(acc_score))
print('Avg accuracy : {}'.format(avg_acc_score))

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
plt.rcParams["figure.figsize"] = (16,9)
# %matplotlib inline

score = np.array([0.8, 0.6, 0.4, 0.2])
y = np.array([1,0,1,0])

# false positive rate
FPR = []
# true positive rate
TPR = []
# Iterate thresholds from 0.0 to 1.0
thresholds = np.arange(0.0, 1.01, 0.2)
# array([0. , 0.2, 0.4, 0.6, 0.8, 1. ])

# get number of positive and negative examples in the dataset
P = sum(y)
N = len(y) - P

# iterate through all thresholds and determine fraction of true positives
# and false positives found at this threshold
for thresh in thresholds:
    FP=0
    TP=0
    thresh = round(thresh,2) #Limiting floats to two decimal points, or threshold 0.6 will be 0.6000000000000001 which gives FP=0
    for i in range(len(score)):
        if (score[i] >= thresh):
            if y[i] == 1:
                TP = TP + 1
            if y[i] == 0:
                FP = FP + 1
    FPR.append(FP/N)
    TPR.append(TP/P)

# FPR [1.0, 1.0, 0.5, 0.5, 0.0, 0.0]
# TPR [1.0, 1.0, 1.0, 0.5, 0.5, 0.0]

# This is the AUC
#you're integrating from right to left. This flips the sign of the result
auc = -1 * np.trapz(TPR, FPR)

plt.plot(FPR, TPR, linestyle='--', marker='o', color='darkorange', lw = 2, label='ROC curve', clip_on=False)
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve, AUC = %.2f'%auc)
plt.legend(loc="lower right")
plt.savefig('AUC_example.png')
plt.show()



# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns
import tempfile
import os
import tensorflow as tf
import numpy as np
from tensorflow import keras
import matplotlib.pyplot as plt
# %load_ext tensorboard
# %matplotlib inline

from sklearn.model_selection import train_test_split

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

from google.colab import files
uploaded = files.upload()

train_data = pd.read_csv('titanic_train.csv')
train_data.head(10)

#Importing required libraries
from sklearn.datasets import load_breast_cancer
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

#Loading the dataset
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

from google.colab import files
uploaded = files.upload()

titanic = pd.read_csv('titanic_train.csv')
titanic.head(10)

#Implementing cross validation

k = 5
kf = KFold(n_splits=k, random_state=None)
model = LogisticRegression(solver= 'liblinear')

acc_score = []

titanic.head(10)

titanic.drop(['passenger_id', 'sibsp', 'parch', 'ticket', 'boat', 'name'], axis=1, inplace=True)
titanic.head(10)

titanic.drop(['cabin', 'home.dest'], axis=1, inplace=True)
titanic.head(10)

gender_num = {'male': 0, 'female': 1}
titanic['sex'] = titanic['sex'].map(gender_num)
titanic.fillna(0)

titanic['age'].fillna(value=titanic['age'].mean(), inplace=True)
titanic.head(10)

titanic.drop(['body'], axis=1, inplace=True)

titanic.head(50)

embarked_num = {'Q': 0, 'S': 1, 'C':2}
titanic['embarked'] = titanic['embarked'].map(embarked_num)
titanic.head(10)

X = titanic.iloc[:,:-1]
y = titanic.iloc[:,-1]

titanic.head(100)

for dataset in [y_train, y_val, y_test]:
  print(round(len(dataset)/len(labels), 2))

titanic.round(2)
titanic.fillna(value=titanic.mean(), inplace=True)

titanic.dtypes

import numpy as np

titanic['pclass'] = titanic['pclass'].astype(np.int64)
titanic['sex'] = titanic['sex'].astype(np.int64)
titanic['survived'] = titanic['survived'].astype(np.int64)
titanic['age'] = titanic['age'].astype(np.int64)
titanic['fare'] = titanic['fare'].astype(np.int64)
titanic['embarked'] = titanic['embarked'].astype(np.int64)

import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

from sklearn.model_selection import train_test_split
#Importing required libraries
from sklearn.datasets import load_breast_cancer
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

features = titanic.drop('survived', axis=1)
labels = titanic['survived']

x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42) #4 datasets created, 60 train
x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42) #breaking up x,y test into test20 validation20

x_train.to_csv('train_features.csv', index = False)
x_val.to_csv('val_features.csv', index = False)
x_test.to_csv('test_features.csv', index = False)

y_train.to_csv('train_labels.csv', index = False)
y_val.to_csv('val_labels.csv', index = False)
y_test.to_csv('test_labels.csv', index = False)

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
import warnings
warnings.filterwarnings('ignore', category=FutureWarning)

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

from google.colab import files
uploaded = files.upload()

tr_features = pd.read_csv('train_features.csv')

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

from google.colab import files
uploaded = files.upload()

tr_labels = pd.read_csv('train_labels.csv')

for train_index , test_index in kf.split(X):
    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]
    y_train , y_test = y[train_index] , y[test_index]

print(X_train)
print(y_train)
print(X_test)
print(y_test)

#train_data.drop(['body'], axis=1, inplace=True)
train_data.head(10)

k = 5
kf = KFold(n_splits=k, random_state=None)
model = LogisticRegression(solver= 'liblinear')

acc_score = []
model.fit(x_train,y_train)
pred_values = model.predict(x_test)

acc = accuracy_score(pred_values , y_test)
acc_score.append(acc)

avg_acc_score = sum(acc_score)/k

print('accuracy of each fold - {}'.format(acc_score))
print('Avg accuracy : {}'.format(avg_acc_score))

accuracy of each fold - [0.9122807017543859, 0.9473684210526315, 0.9736842105263158, 0.9736842105263158, 0.9557522123893806]
Avg accuracy : 0.952553951249806

"""accuracy of each fold - [0.9122807017543859, 0.9473684210526315, 0.9736842105263158, 0.9736842105263158, 0.9557522123893806]
Avg accuracy : 0.952553951249806
In the code above we implemente
"""