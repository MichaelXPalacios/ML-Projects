# -*- coding: utf-8 -*-
"""pruning

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aiAWzy5he7O9BABYVvqb-P4XglqH9adA

Original MNIST - 4 epochs, 0.1 validation
"""

# Commented out IPython magic to ensure Python compatibility.
! pip install -q tensorflow-model-optimization
import tempfile
import os

import tensorflow as tf
import numpy as np

from tensorflow import keras
import matplotlib.pyplot as plt

# %load_ext tensorboard

# Load MNIST dataset
mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
#class_names = ['mfr',	'calories',	'protein',	'fat',	'sodium',	'fiber',	'carbo',	'sugars',	'potass',	'vitamins',	'shelf',	'cups',	'rating']

# Normalize the input image so that each pixel value is between 0 to 1.
train_images = train_images / 255.0
test_images = test_images / 255.0

# Define the model architecture.
model = keras.Sequential([
  keras.layers.InputLayer(input_shape=(28, 28)),
  keras.layers.Reshape(target_shape=(28, 28, 1)),
  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),
  keras.layers.MaxPooling2D(pool_size=(2, 2)),
  keras.layers.Flatten(),
  keras.layers.Dense(10)
])

# Train the digit classification model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(
  train_images,
  train_labels,
  epochs=4,
  validation_split=0.1,
)

_, baseline_model_accuracy = model.evaluate(
    test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)

_, keras_file = tempfile.mkstemp('.h5')
tf.keras.models.save_model(model, keras_file, include_optimizer=False)
print('Saved baseline model to:', keras_file)
prediction = model.predict(test_images)
print ("Prediction: ", prediction)
print ("Prediction: ", class_names[np.argmax(prediction[0])])

for i in range(5):
 plt.grid(False)
 plt.imshow(test_images[i], cmap=plt.cm.binary)
 plt.xlabel("Actual: " + class_names[test_labels[i]])
 plt.title("Prediction: " + class_names[np.argmax(prediction[i])])
 plt.show()

"""MNIST - epochs 10, validation 0.2"""

# Commented out IPython magic to ensure Python compatibility.
! pip install -q tensorflow-model-optimization
import tempfile
import os

import tensorflow as tf
import numpy as np

from tensorflow import keras
import matplotlib.pyplot as plt

# %load_ext tensorboard

# Load MNIST dataset
mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
#class_names = ['mfr',	'calories',	'protein',	'fat',	'sodium',	'fiber',	'carbo',	'sugars',	'potass',	'vitamins',	'shelf',	'cups',	'rating']

# Normalize the input image so that each pixel value is between 0 to 1.
train_images = train_images / 255.0
test_images = test_images / 255.0

# Define the model architecture.
model = keras.Sequential([
  keras.layers.InputLayer(input_shape=(28, 28)),
  keras.layers.Reshape(target_shape=(28, 28, 1)),
  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),
  keras.layers.MaxPooling2D(pool_size=(2, 2)),
  keras.layers.Flatten(),
  keras.layers.Dense(10)
])

# Train the digit classification model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(
  train_images,
  train_labels,
  epochs=10,
  validation_split=0.2,
)

_, baseline_model_accuracy = model.evaluate(
    test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)

_, keras_file = tempfile.mkstemp('.h5')
#tf.keras.models.save_model(model, keras_file, include_optimizer=False)
#print('Saved baseline model to:', keras_file)
prediction = model.predict(test_images)
print ("Prediction: ", prediction)
print ("Prediction: ", class_names[np.argmax(prediction[0])])

for i in range(5):
 plt.grid(False)
 plt.imshow(test_images[i], cmap=plt.cm.binary)
 plt.xlabel("Actual: " + class_names[test_labels[i]])
 plt.title("Prediction: " + class_names[np.argmax(prediction[i])])
 plt.show()

"""MNIST Pruning - 4 epochs, 128 batch, 0.1 validation , and TF pruning"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow_model_optimization as tfmot

prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude

# Compute end step to finish pruning after 2 epochs.
batch_size = 128
epochs = 4
validation_split = 0.1 # 10% of training set will be used for validation set.

num_images = train_images.shape[0] * (1 - validation_split)
end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs

# Define model for pruning.
pruning_params = {
      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.25,
                                                               final_sparsity=0.80,
                                                               begin_step=0,
                                                               end_step=end_step)
}

model_for_pruning = prune_low_magnitude(model, **pruning_params)

# `prune_low_magnitude` requires a recompile.
model_for_pruning.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model_for_pruning.summary()

logdir = tempfile.mkdtemp()

callbacks = [
  tfmot.sparsity.keras.UpdatePruningStep(),
  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),
]

model_for_pruning.fit(train_images, train_labels,
                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,
                  callbacks=callbacks)

_, model_for_pruning_accuracy = model_for_pruning.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Pruned test accuracy:', model_for_pruning_accuracy)

#docs_infra: no_execute
# %tensorboard --logdir={logdir}

print('Baseline test accuracy:', baseline_model_accuracy)

_, keras_file = tempfile.mkstemp('.h5')
tf.keras.models.save_model(model, keras_file, include_optimizer=False)
print('Saved baseline model to:', keras_file)
prediction = model.predict(test_images)
print ("Prediction: ", prediction)
print ("Prediction: ", class_names[np.argmax(prediction[0])])

#for i in range(5):
 #plt.grid(False)
 #plt.imshow(test_images[i], cmap=plt.cm.binary)
 #plt.xlabel("Actual: " + class_names[test_labels[i]])
 #plt.title("Prediction: " + class_names[np.argmax(prediction[i])])
 #plt.show()

"""Batch 128, epoch 10, val 0.1, tensorflow pruning"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow_model_optimization as tfmot

prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude

# Compute end step to finish pruning after 2 epochs.
batch_size = 128
epochs = 10
validation_split = 0.1 # 10% of training set will be used for validation set.

num_images = train_images.shape[0] * (1 - validation_split)
end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs

# Define model for pruning.
pruning_params = {
      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.25,
                                                               final_sparsity=0.80,
                                                               begin_step=0,
                                                               end_step=end_step)
}

model_for_pruning = prune_low_magnitude(model, **pruning_params)

# `prune_low_magnitude` requires a recompile.
model_for_pruning.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model_for_pruning.summary()

logdir = tempfile.mkdtemp()

callbacks = [
  tfmot.sparsity.keras.UpdatePruningStep(),
  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),
]

model_for_pruning.fit(train_images, train_labels,
                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,
                  callbacks=callbacks)

_, model_for_pruning_accuracy = model_for_pruning.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Pruned test accuracy:', model_for_pruning_accuracy)

#docs_infra: no_execute
# %tensorboard --logdir={logdir}

print('Baseline test accuracy:', baseline_model_accuracy)

_, keras_file = tempfile.mkstemp('.h5')
tf.keras.models.save_model(model, keras_file, include_optimizer=False)
print('Saved baseline model to:', keras_file)
prediction = model.predict(test_images)
print ("Prediction: ", prediction)
print ("Prediction: ", class_names[np.argmax(prediction[0])])

#for i in range(5):
 #plt.grid(False)
 #plt.imshow(test_images[i], cmap=plt.cm.binary)
 #plt.xlabel("Actual: " + class_names[test_labels[i]])
 #plt.title("Prediction: " + class_names[np.argmax(prediction[i])])
 #plt.show()

"""batch_size = 256
epochs = 4
validation_split = 0.1
TF Pruning
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow_model_optimization as tfmot

prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude

# Compute end step to finish pruning after 2 epochs.
batch_size = 256
epochs = 4
validation_split = 0.1 # 10% of training set will be used for validation set.

num_images = train_images.shape[0] * (1 - validation_split)
end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs

# Define model for pruning.
pruning_params = {
      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.25,
                                                               final_sparsity=0.80,
                                                               begin_step=0,
                                                               end_step=end_step)
}

model_for_pruning = prune_low_magnitude(model, **pruning_params)

# `prune_low_magnitude` requires a recompile.
model_for_pruning.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model_for_pruning.summary()

logdir = tempfile.mkdtemp()

callbacks = [
  tfmot.sparsity.keras.UpdatePruningStep(),
  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),
]

model_for_pruning.fit(train_images, train_labels,
                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,
                  callbacks=callbacks)

_, model_for_pruning_accuracy = model_for_pruning.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Pruned test accuracy:', model_for_pruning_accuracy)

#docs_infra: no_execute
# %tensorboard --logdir={logdir}

print('Baseline test accuracy:', baseline_model_accuracy)
#for i in range(5):
 #plt.grid(False)
 #plt.imshow(test_images[i], cmap=plt.cm.binary)
 #plt.xlabel("Actual: " + class_names[test_labels[i]])
 #plt.title("Prediction: " + class_names[np.argmax(prediction[i])])
 #plt.show()

"""batch_size = 512
epochs = 4
validation_split = 0.1
TF Pruning
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow_model_optimization as tfmot

prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude

# Compute end step to finish pruning after 2 epochs.
batch_size = 512
epochs = 4
validation_split = 0.1 # 10% of training set will be used for validation set.

num_images = train_images.shape[0] * (1 - validation_split)
end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs

# Define model for pruning.
pruning_params = {
      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.25,
                                                               final_sparsity=0.80,
                                                               begin_step=0,
                                                               end_step=end_step)
}

model_for_pruning = prune_low_magnitude(model, **pruning_params)

# `prune_low_magnitude` requires a recompile.
model_for_pruning.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model_for_pruning.summary()

logdir = tempfile.mkdtemp()

callbacks = [
  tfmot.sparsity.keras.UpdatePruningStep(),
  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),
]

model_for_pruning.fit(train_images, train_labels,
                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,
                  callbacks=callbacks)

_, model_for_pruning_accuracy = model_for_pruning.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Pruned test accuracy:', model_for_pruning_accuracy)

#docs_infra: no_execute
# %tensorboard --logdir={logdir}

print('Baseline test accuracy:', baseline_model_accuracy)

_, keras_file = tempfile.mkstemp('.h5')
tf.keras.models.save_model(model, keras_file, include_optimizer=False)
print('Saved baseline model to:', keras_file)
prediction = model.predict(test_images)
print ("Prediction: ", prediction)
print ("Prediction: ", class_names[np.argmax(prediction[0])])

#for i in range(5):
 #plt.grid(False)
 #plt.imshow(test_images[i], cmap=plt.cm.binary)
 #plt.xlabel("Actual: " + class_names[test_labels[i]])
 #plt.title("Prediction: " + class_names[np.argmax(prediction[i])])
 #plt.show()

"""batch_size = 256
epochs = 4
validation_split = 0.2
TF Pruning
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow_model_optimization as tfmot

prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude

# Compute end step to finish pruning after 2 epochs.
batch_size = 256
epochs = 4
validation_split = 0.2 # 20% of training set will be used for validation set.

num_images = train_images.shape[0] * (1 - validation_split)
end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs

# Define model for pruning.
pruning_params = {
      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.25,
                                                               final_sparsity=0.80,
                                                               begin_step=0,
                                                               end_step=end_step)
}

model_for_pruning = prune_low_magnitude(model, **pruning_params)

# `prune_low_magnitude` requires a recompile.
model_for_pruning.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model_for_pruning.summary()

logdir = tempfile.mkdtemp()

callbacks = [
  tfmot.sparsity.keras.UpdatePruningStep(),
  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),
]

model_for_pruning.fit(train_images, train_labels,
                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,
                  callbacks=callbacks)

_, model_for_pruning_accuracy = model_for_pruning.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Pruned test accuracy:', model_for_pruning_accuracy)

#docs_infra: no_execute
# %tensorboard --logdir={logdir}

print('Baseline test accuracy:', baseline_model_accuracy)

"""batch_size = 256
epochs = 10
validation_split = 0.2
TF Pruning
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow_model_optimization as tfmot

prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude

# Compute end step to finish pruning after 2 epochs.
batch_size = 256
epochs = 10
validation_split = 0.2 # 10% of training set will be used for validation set.

num_images = train_images.shape[0] * (1 - validation_split)
end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs

# Define model for pruning.
pruning_params = {
      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.25,
                                                               final_sparsity=0.80,
                                                               begin_step=0,
                                                               end_step=end_step)
}

model_for_pruning = prune_low_magnitude(model, **pruning_params)

# `prune_low_magnitude` requires a recompile.
model_for_pruning.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model_for_pruning.summary()

logdir = tempfile.mkdtemp()

callbacks = [
  tfmot.sparsity.keras.UpdatePruningStep(),
  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),
]

model_for_pruning.fit(train_images, train_labels,
                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,
                  callbacks=callbacks)

_, model_for_pruning_accuracy = model_for_pruning.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Pruned test accuracy:', model_for_pruning_accuracy)

#docs_infra: no_execute
# %tensorboard --logdir={logdir}

print('Baseline test accuracy:', baseline_model_accuracy)

"""batch_size = 64
epochs = 4
validation_split = 0.1
TF Pruning
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow_model_optimization as tfmot

prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude

# Compute end step to finish pruning after 2 epochs.
batch_size = 64
epochs = 4
validation_split = 0.1 # 10% of training set will be used for validation set.

num_images = train_images.shape[0] * (1 - validation_split)
end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs

# Define model for pruning.
pruning_params = {
      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.25,
                                                               final_sparsity=0.80,
                                                               begin_step=0,
                                                               end_step=end_step)
}

model_for_pruning = prune_low_magnitude(model, **pruning_params)

# `prune_low_magnitude` requires a recompile.
model_for_pruning.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model_for_pruning.summary()

logdir = tempfile.mkdtemp()

callbacks = [
  tfmot.sparsity.keras.UpdatePruningStep(),
  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),
]

model_for_pruning.fit(train_images, train_labels,
                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,
                  callbacks=callbacks)

_, model_for_pruning_accuracy = model_for_pruning.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Pruned test accuracy:', model_for_pruning_accuracy)

#docs_infra: no_execute
# %tensorboard --logdir={logdir}

print('Baseline test accuracy:', baseline_model_accuracy)

"""batch_size = 32
epochs = 4
validation_split = 0.1
TF Pruning
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow_model_optimization as tfmot

prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude

# Compute end step to finish pruning after 2 epochs.
batch_size = 32
epochs = 4
validation_split = 0.1 # 10% of training set will be used for validation set.

num_images = train_images.shape[0] * (1 - validation_split)
end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs

# Define model for pruning.
pruning_params = {
      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.25,
                                                               final_sparsity=0.80,
                                                               begin_step=0,
                                                               end_step=end_step)
}

model_for_pruning = prune_low_magnitude(model, **pruning_params)

# `prune_low_magnitude` requires a recompile.
model_for_pruning.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model_for_pruning.summary()

logdir = tempfile.mkdtemp()

callbacks = [
  tfmot.sparsity.keras.UpdatePruningStep(),
  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),
]

model_for_pruning.fit(train_images, train_labels,
                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,
                  callbacks=callbacks)

_, model_for_pruning_accuracy = model_for_pruning.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Pruned test accuracy:', model_for_pruning_accuracy)

#docs_infra: no_execute
# %tensorboard --logdir={logdir}

print('Baseline test accuracy:', baseline_model_accuracy)

# Commented out IPython magic to ensure Python compatibility.
import tensorflow_model_optimization as tfmot

prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude

# Compute end step to finish pruning after 2 epochs.
batch_size = 64
epochs = 4
validation_split = 0.2 # 10% of training set will be used for validation set.

num_images = train_images.shape[0] * (1 - validation_split)
end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs

# Define model for pruning.
pruning_params = {
      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.25,
                                                               final_sparsity=0.80,
                                                               begin_step=0,
                                                               end_step=end_step)
}

model_for_pruning = prune_low_magnitude(model, **pruning_params)

# `prune_low_magnitude` requires a recompile.
model_for_pruning.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model_for_pruning.summary()

logdir = tempfile.mkdtemp()

callbacks = [
  tfmot.sparsity.keras.UpdatePruningStep(),
  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),
]

model_for_pruning.fit(train_images, train_labels,
                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,
                  callbacks=callbacks)

_, model_for_pruning_accuracy = model_for_pruning.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Pruned test accuracy:', model_for_pruning_accuracy)

#docs_infra: no_execute
# %tensorboard --logdir={logdir}

print('Baseline test accuracy:', baseline_model_accuracy)

"""TFLite Quantization, 10 Epochs"""

# Importing libraries
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import time

data = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = data.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

plt.imshow(train_images[6], cmap=plt.cm.binary)
train_images = train_images/255.0
test_images = test_images/255.0

model = keras.Sequential([
 keras.layers.Flatten(input_shape=(28,28)),
 keras.layers.Dense(128, activation="relu"),
 keras.layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy",
metrics=["accuracy"])

# Uncomment to train the model
# model.fit(train_images, train_labels, epochs=10)

# Convert the model to TFLite with quantization
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
quantized_tflite_model = converter.convert()

# Save the quantized model to a file (optional)
with open('quantized_model.tflite', 'wb') as f:
    f.write(quantized_tflite_model)

# Load TFLite model and allocate tensors
interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)
interpreter.allocate_tensors()

# Get input and output tensors
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test the TFLite model
input_shape = input_details[0]['shape']
# Cast test_images to FLOAT32
test_images_float32 = np.float32(test_images)

interpreter.invoke()

# Test the TFLite model on individual images
tflite_predictions = []

for img in test_images_float32:
    # Reshape the image to (1, 28, 28) as the interpreter expects this shape
    img_reshaped = img.reshape(1, 28, 28)
    interpreter.set_tensor(input_details[0]['index'], img_reshaped)
    interpreter.invoke()
    tflite_predictions.append(interpreter.get_tensor(output_details[0]['index']))

# Convert list of predictions to numpy array for easier indexing
tflite_predictions = np.array(tflite_predictions).squeeze()

for i in range(5):
    plt.grid(False)
    plt.imshow(test_images[i], cmap=plt.cm.binary)
    plt.xlabel("Actual: " + class_names[test_labels[i]])
    plt.title("Prediction: " + class_names[np.argmax(tflite_predictions[i])])
    plt.show()

start_time = time.time()

history = model.fit(train_images, train_labels, epochs=10, verbose=0)  # Set verbose=0 to suppress the default print

end_time = time.time()
time_per_epoch = (end_time - start_time) / 10  # Assuming 10 epochs

# Extract accuracy and loss from the history object
acc = history.history['accuracy']
loss = history.history['loss']

# Print the accuracy, loss, and time per epoch
for epoch in range(10):
    print(f"Epoch {epoch+1}:")
    print(f"Accuracy: {acc[epoch]*100:.2f}%")
    print(f"Loss: {loss[epoch]:.4f}")
    print(f"Time taken: {time_per_epoch:.2f} seconds")
    print("----------------------------")

"""TFLite Quant, epoch 20"""

# Importing libraries
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import time

data = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = data.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

plt.imshow(train_images[6], cmap=plt.cm.binary)
train_images = train_images/255.0
test_images = test_images/255.0

model = keras.Sequential([
 keras.layers.Flatten(input_shape=(28,28)),
 keras.layers.Dense(128, activation="relu"),
 keras.layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy",
metrics=["accuracy"])

# Uncomment to train the model
# model.fit(train_images, train_labels, epochs=10)

# Convert the model to TFLite with quantization
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
quantized_tflite_model = converter.convert()

# Save the quantized model to a file (optional)
with open('quantized_model.tflite', 'wb') as f:
    f.write(quantized_tflite_model)

# Load TFLite model and allocate tensors
interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)
interpreter.allocate_tensors()

# Get input and output tensors
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test the TFLite model
input_shape = input_details[0]['shape']
# Cast test_images to FLOAT32
test_images_float32 = np.float32(test_images)

interpreter.invoke()

# Test the TFLite model on individual images
tflite_predictions = []

for img in test_images_float32:
    # Reshape the image to (1, 28, 28) as the interpreter expects this shape
    img_reshaped = img.reshape(1, 28, 28)
    interpreter.set_tensor(input_details[0]['index'], img_reshaped)
    interpreter.invoke()
    tflite_predictions.append(interpreter.get_tensor(output_details[0]['index']))

# Convert list of predictions to numpy array for easier indexing
tflite_predictions = np.array(tflite_predictions).squeeze()

for i in range(5):
    plt.grid(False)
    plt.imshow(test_images[i], cmap=plt.cm.binary)
    plt.xlabel("Actual: " + class_names[test_labels[i]])
    plt.title("Prediction: " + class_names[np.argmax(tflite_predictions[i])])
    plt.show()

start_time = time.time()

history = model.fit(train_images, train_labels, epochs=20, verbose=0)  # Set verbose=0 to suppress the default print

end_time = time.time()
time_per_epoch = (end_time - start_time) / 20  # Assuming 10 epochs

# Extract accuracy and loss from the history object
acc = history.history['accuracy']
loss = history.history['loss']

# Print the accuracy, loss, and time per epoch
for epoch in range(20):
    print(f"Epoch {epoch+1}:")
    print(f"Accuracy: {acc[epoch]*100:.2f}%")
    print(f"Loss: {loss[epoch]:.4f}")
    print(f"Time taken: {time_per_epoch:.2f} seconds")
    print("----------------------------")

"""Quantization, Pruning, epoch 10"""

! pip install -q tensorflow-model-optimization
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import time
import tensorflow_model_optimization as tfmot

# Load data
data = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = data.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images = train_images/255.0
test_images = test_images/255.0

# Define model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Train model
start_time = time.time()
history = model.fit(train_images, train_labels, epochs=10, verbose=0)
end_time = time.time()
time_per_epoch = (end_time - start_time) / 10

# Print training metrics
acc = history.history['accuracy']
loss = history.history['loss']
for epoch in range(10):
    print(f"Epoch {epoch+1}:")
    print(f"Accuracy: {acc[epoch]*100:.2f}%")
    print(f"Loss: {loss[epoch]:.4f}")
    print(f"Time taken: {time_per_epoch:.2f} seconds")
    print("----------------------------")

# Model Pruning
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0, final_sparsity=0.5, begin_step=0, end_step=len(train_images)*10)
model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, pruning_schedule=pruning_schedule)
model_for_pruning.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])
model_for_pruning.fit(train_images, train_labels, epochs=2, callbacks=[tfmot.sparsity.keras.UpdatePruningStep()])

# Model Quantization
converter = tf.lite.TFLiteConverter.from_keras_model(model_for_pruning)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
quantized_and_pruned_tflite_model = converter.convert()

# Save compressed model
with open('compressed_model.tflite', 'wb') as f:
    f.write(quantized_and_pruned_tflite_model)

print("Model compressed and saved as compressed_model.tflite")

! pip install -q tensorflow-model-optimization

import tensorflow as tf
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import accuracy_score, precision_score
import time
import numpy as np
import tensorflow_model_optimization as tfmot

# Load data using TensorFlow
(data_train, labels_train), (data_test, labels_test) = tf.keras.datasets.fashion_mnist.load_data()

# Convert data to PyTorch tensors
data_train, labels_train = torch.tensor(data_train, dtype=torch.float32), torch.tensor(labels_train, dtype=torch.int64)
data_test, labels_test = torch.tensor(data_test, dtype=torch.float32), torch.tensor(labels_test, dtype=torch.int64)

# Normalize data
data_train /= 255.0
data_test /= 255.0

# Create DataLoader
train_dataset = TensorDataset(data_train, labels_train)
test_dataset = TensorDataset(data_test, labels_test)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# Define the model
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(28*28, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = x.view(-1, 28*28)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

model = Net()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Train the model
for epoch in range(10):
    for data, target in train_loader:
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

# Test the model
def test_model(model, loader):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for data, target in loader:
            outputs = model(data)
            _, predicted = torch.max(outputs.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    accuracy = 100 * correct / total
    return accuracy

original_accuracy = test_model(model, test_loader)
print(f"Original Model Accuracy: {original_accuracy}%")

# Prune the model
import torch.nn.utils.prune as prune

parameters_to_prune = (
    (model.fc1, 'weight'),
    (model.fc2, 'weight'),
)

prune.global_unstructured(
    parameters_to_prune,
    pruning_method=prune.L1Unstructured,
    amount=0.5,
)

pruned_accuracy = test_model(model, test_loader)
print(f"Pruned Model Accuracy: {pruned_accuracy}%")

# TODO: Quantize the model (PyTorch's quantization utilities can be used here)

# TODO: Serialize the model (PyTorch's torch.save or ONNX can be used)

# TODO: Compare the accuracy, precision, and timing between the original, pruned, quantized, and serialized models.

import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import precision_score
import numpy as np
import time
import tensorflow_model_optimization as tfmot

# Load data
data = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = data.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images = train_images/255.0
test_images = test_images/255.0

# Define model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Train model
model.fit(train_images, train_labels, epochs=10)

# Evaluate original model
start_time = time.time()
original_preds = model.predict(test_images)
original_time = time.time() - start_time
original_accuracy = np.mean(np.argmax(original_preds, axis=1) == test_labels)
original_precision = precision_score(test_labels, np.argmax(original_preds, axis=1), average='weighted')

# Model Pruning
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0, final_sparsity=0.5, begin_step=0, end_step=len(train_images)*10)
model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, pruning_schedule=pruning_schedule)
model_for_pruning.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])
model_for_pruning.fit(train_images, train_labels, epochs=2, callbacks=[tfmot.sparsity.keras.UpdatePruningStep()])

# Evaluate pruned model
start_time = time.time()
pruned_preds = model_for_pruning.predict(test_images)
pruned_time = time.time() - start_time
pruned_accuracy = np.mean(np.argmax(pruned_preds, axis=1) == test_labels)
pruned_precision = precision_score(test_labels, np.argmax(pruned_preds, axis=1), average='weighted')

# Model Quantization
converter = tf.lite.TFLiteConverter.from_keras_model(model_for_pruning)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
quantized_and_pruned_tflite_model = converter.convert()

# Evaluate quantized model using TFLite interpreter
interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test the TFLite model
input_shape = input_details[0]['shape']
# Cast test_images to FLOAT32
test_images_float32 = np.float32(test_images)
interpreter.set_tensor(input_details[0]['index'], test_images_float32)

interpreter.invoke()
quantized_time = time.time() - start_time

tflite_predictions = []
for img in test_images:
    interpreter.set_tensor(input_details[0]['index'], img[None, ...])
    interpreter.invoke()
    tflite_predictions.append(interpreter.get_tensor(output_details[0]['index']))
tflite_predictions = np.array(tflite_predictions).squeeze()

quantized_accuracy = np.mean(np.argmax(tflite_predictions, axis=1) == test_labels)
quantized_precision = precision_score(test_labels, np.argmax(tflite_predictions, axis=1), average='weighted')

# Print results
print(f"Original Model: Accuracy = {original_accuracy:.4f}, Precision = {original_precision:.4f}, Time = {original_time:.4f} seconds")
print(f"Pruned Model: Accuracy = {pruned_accuracy:.4f}, Precision = {pruned_precision:.4f}, Time = {pruned_time:.4f} seconds")
print(f"Quantized Model: Accuracy = {quantized_accuracy:.4f}, Precision = {quantized_precision:.4f}, Time = {quantized_time:.4f} seconds")

"""Model, pruning vs quantization with tensorflow

Hand made prune
"""

import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import precision_score
import numpy as np
import time

# Load data
data = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = data.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images = train_images/255.0
test_images = test_images/255.0

# Ensure the test images are of type FLOAT32
test_images = test_images.astype(np.float32)

# Define model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Train model
model.fit(train_images, train_labels, epochs=10)

# Simple magnitude-based pruning
threshold = 0.01  # Define a threshold
for layer in model.layers:
    if isinstance(layer, keras.layers.Dense):
        weights = layer.get_weights()[0]
        biases = layer.get_weights()[1]

        # Set small weights to zero
        weights[np.abs(weights) < threshold] = 0

        # Update the layer's weights
        layer.set_weights([weights, biases])

# Optionally, you can fine-tune the model after pruning
# model.fit(train_images, train_labels, epochs=2)

# Evaluate original model
start_time = time.time()
original_preds = model.predict(test_images)
original_time = time.time() - start_time
original_accuracy = np.mean(np.argmax(original_preds, axis=1) == test_labels)
original_precision = precision_score(test_labels, np.argmax(original_preds, axis=1), average='weighted')

# Print results
print(f"Original Model: Accuracy = {original_accuracy:.4f}, Precision = {original_precision:.4f}, Time = {original_time:.4f} seconds")

"""Keras Pruning"""

import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import precision_score
import numpy as np
import time

# Load data
data = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = data.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images = train_images/255.0
test_images = test_images/255.0

# Ensure the test images are of type FLOAT32
test_images = test_images.astype(np.float32)

# Define model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Define pruning function
def prune_weights(weights, sparsity):
    """Prune weights using magnitude-based pruning."""
    threshold = np.percentile(np.abs(weights), sparsity * 100)
    pruned_weights = np.where(np.abs(weights) < threshold, 0., weights)
    return pruned_weights

# Define a pruning schedule
initial_sparsity = 0.1
final_sparsity = 0.5
epochs = 10
sparsity_increase_per_epoch = (final_sparsity - initial_sparsity) / epochs

# Train model with pruning
current_sparsity = initial_sparsity
for epoch in range(epochs):
    # Train for one epoch
    model.fit(train_images, train_labels, epochs=1)

    # Prune weights based on the current sparsity level
    for layer in model.layers:
        if isinstance(layer, keras.layers.Dense):
            weights, biases = layer.get_weights()
            pruned_weights = prune_weights(weights, current_sparsity)
            layer.set_weights([pruned_weights, biases])

    # Increase the sparsity for the next epoch
    current_sparsity += sparsity_increase_per_epoch

# Evaluate the model
start_time = time.time()
original_preds = model.predict(test_images)
original_time = time.time() - start_time
original_accuracy = np.mean(np.argmax(original_preds, axis=1) == test_labels)
original_precision = precision_score(test_labels, np.argmax(original_preds, axis=1), average='weighted')

# Print results
print(f"Pruned Model: Accuracy = {original_accuracy:.4f}, Precision = {original_precision:.4f}, Time = {original_time:.4f} seconds")

"""Pruning without library

"""

import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import precision_score
import numpy as np
import time

# Load data
data = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = data.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images = train_images/255.0
test_images = test_images/255.0

# Ensure the test images are of type FLOAT32
test_images = test_images.astype(np.float32)

# Define model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Define pruning function
def prune_weights(weights, sparsity):
    """Prune weights using magnitude-based pruning."""
    threshold = np.percentile(np.abs(weights), sparsity * 50)
    pruned_weights = np.where(np.abs(weights) < threshold, 0., weights)
    return pruned_weights

# Define a pruning schedule
initial_sparsity = 0.3
final_sparsity = 0.6
epochs = 10
sparsity_increase_per_epoch = (final_sparsity - initial_sparsity) / epochs

# Train model with pruning
current_sparsity = initial_sparsity
for epoch in range(epochs):
    # Train for one epoch
    model.fit(train_images, train_labels, epochs=1)

    # Prune weights based on the current sparsity level
    for layer in model.layers:
        if isinstance(layer, keras.layers.Dense):
            weights, biases = layer.get_weights()
            pruned_weights = prune_weights(weights, current_sparsity)
            layer.set_weights([pruned_weights, biases])

    # Increase the sparsity for the next epoch
    current_sparsity += sparsity_increase_per_epoch

# Evaluate the model
start_time = time.time()
original_preds = model.predict(test_images)
original_time = time.time() - start_time
original_accuracy = np.mean(np.argmax(original_preds, axis=1) == test_labels)
original_precision = precision_score(test_labels, np.argmax(original_preds, axis=1), average='weighted')

# Print results
print(f"Pruned Model: Accuracy = {original_accuracy:.4f}, Precision = {original_precision:.4f}, Time = {original_time:.4f} seconds")

"""Quanization without imports, 8 bits
Quantized Model: Accuracy = 0.8804, Precision = 0.8820, Time = 1.4298 seconds
"""

import numpy as np
from tensorflow import keras
import time
from sklearn.metrics import precision_score

def quantize_weights(weights, num_bits):
    """Quantize the weights to a specific number of bits."""
    min_val = np.min(weights)
    max_val = np.max(weights)

    # Calculate the scale and zero point
    scale = (max_val - min_val) / (2**num_bits - 1)
    zero_point = int(0.5 - min_val / scale)

    # Quantize the weights
    quantized_weights = np.round((weights - min_val) / scale) + zero_point

    # Dequantize the weights to get the approximate original values
    dequantized_weights = (quantized_weights - zero_point) * scale + min_val

    return dequantized_weights

# Load data
data = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = data.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images = train_images/255.0
test_images = test_images/255.0

# Ensure the test images are of type FLOAT32
test_images = test_images.astype(np.float32)

# Define model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Train model
model.fit(train_images, train_labels, epochs=10)

# Quantize the weights of the first dense layer
weights, biases = model.layers[1].get_weights()
quantized_weights = quantize_weights(weights, num_bits=8)
model.layers[1].set_weights([quantized_weights, biases])

# Evaluate the quantized model
start_time = time.time()
quantized_preds = model.predict(test_images)
quantized_time = time.time() - start_time
quantized_accuracy = np.mean(np.argmax(quantized_preds, axis=1) == test_labels)
quantized_precision = precision_score(test_labels, np.argmax(quantized_preds, axis=1), average='weighted')

# Print results
print(f"Quantized Model: Accuracy = {quantized_accuracy:.4f}, Precision = {quantized_precision:.4f}, Time = {quantized_time:.4f} seconds")

"""Quant OOTB,num 4 bits
Quantized Model: Accuracy = 0.8768, Precision = 0.8788, Time = 0.7986 seconds
"""

import numpy as np
from tensorflow import keras
import time
from sklearn.metrics import precision_score

def quantize_weights(weights, num_bits):
    """Quantize the weights to a specific number of bits."""
    min_val = np.min(weights)
    max_val = np.max(weights)

    # Calculate the scale and zero point
    scale = (max_val - min_val) / (2**num_bits - 1)
    zero_point = int(0.5 - min_val / scale)

    # Quantize the weights
    quantized_weights = np.round((weights - min_val) / scale) + zero_point

    # Dequantize the weights to get the approximate original values
    dequantized_weights = (quantized_weights - zero_point) * scale + min_val

    return dequantized_weights

# Load data
data = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = data.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images = train_images/255.0
test_images = test_images/255.0

# Ensure the test images are of type FLOAT32
test_images = test_images.astype(np.float32)

# Define model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Train model
model.fit(train_images, train_labels, epochs=10)

# Quantize the weights of the first dense layer
weights, biases = model.layers[1].get_weights()
quantized_weights = quantize_weights(weights, num_bits=4)
model.layers[1].set_weights([quantized_weights, biases])

# Evaluate the quantized model
start_time = time.time()
quantized_preds = model.predict(test_images)
quantized_time = time.time() - start_time
quantized_accuracy = np.mean(np.argmax(quantized_preds, axis=1) == test_labels)
quantized_precision = precision_score(test_labels, np.argmax(quantized_preds, axis=1), average='weighted')

# Print results
print(f"Quantized Model: Accuracy = {quantized_accuracy:.4f}, Precision = {quantized_precision:.4f}, Time = {quantized_time:.4f} seconds")

"""Quan OOTB, 16 num bits
Quantized Model: Accuracy = 0.8843, Precision = 0.8839, Time = 1.3728 seconds
"""

import numpy as np
from tensorflow import keras
import time
from sklearn.metrics import precision_score

def quantize_weights(weights, num_bits):
    """Quantize the weights to a specific number of bits."""
    min_val = np.min(weights)
    max_val = np.max(weights)

    # Calculate the scale and zero point
    scale = (max_val - min_val) / (2**num_bits - 1)
    zero_point = int(0.5 - min_val / scale)

    # Quantize the weights
    quantized_weights = np.round((weights - min_val) / scale) + zero_point

    # Dequantize the weights to get the approximate original values
    dequantized_weights = (quantized_weights - zero_point) * scale + min_val

    return dequantized_weights

# Load data
data = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = data.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images = train_images/255.0
test_images = test_images/255.0

# Ensure the test images are of type FLOAT32
test_images = test_images.astype(np.float32)

# Define model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Train model
model.fit(train_images, train_labels, epochs=10)

# Quantize the weights of the first dense layer
weights, biases = model.layers[1].get_weights()
quantized_weights = quantize_weights(weights, num_bits=16)
model.layers[1].set_weights([quantized_weights, biases])

# Evaluate the quantized model
start_time = time.time()
quantized_preds = model.predict(test_images)
quantized_time = time.time() - start_time
quantized_accuracy = np.mean(np.argmax(quantized_preds, axis=1) == test_labels)
quantized_precision = precision_score(test_labels, np.argmax(quantized_preds, axis=1), average='weighted')

# Print results
print(f"Quantized Model: Accuracy = {quantized_accuracy:.4f}, Precision = {quantized_precision:.4f}, Time = {quantized_time:.4f} seconds")

"""Quant OOTB, 64 bits
Quantized Model: Accuracy = 0.8764, Precision = 0.8817, Time = 0.7704 seconds
"""

import numpy as np
from tensorflow import keras
import time
from sklearn.metrics import precision_score

def quantize_weights(weights, num_bits):
    """Quantize the weights to a specific number of bits."""
    min_val = np.min(weights)
    max_val = np.max(weights)

    # Calculate the scale and zero point
    scale = (max_val - min_val) / (2**num_bits - 1)
    zero_point = int(0.5 - min_val / scale)

    # Quantize the weights
    quantized_weights = np.round((weights - min_val) / scale) + zero_point

    # Dequantize the weights to get the approximate original values
    dequantized_weights = (quantized_weights - zero_point) * scale + min_val

    return dequantized_weights

# Load data
data = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = data.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images = train_images/255.0
test_images = test_images/255.0

# Ensure the test images are of type FLOAT32
test_images = test_images.astype(np.float32)

# Define model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Train model
model.fit(train_images, train_labels, epochs=10)

# Quantize the weights of the first dense layer
weights, biases = model.layers[1].get_weights()
quantized_weights = quantize_weights(weights, num_bits=32)
model.layers[1].set_weights([quantized_weights, biases])

# Evaluate the quantized model
start_time = time.time()
quantized_preds = model.predict(test_images)
quantized_time = time.time() - start_time
quantized_accuracy = np.mean(np.argmax(quantized_preds, axis=1) == test_labels)
quantized_precision = precision_score(test_labels, np.argmax(quantized_preds, axis=1), average='weighted')

# Print results
print(f"Quantized Model: Accuracy = {quantized_accuracy:.4f}, Precision = {quantized_precision:.4f}, Time = {quantized_time:.4f} seconds")

"""64 bits and 256 bits in layer 1
Quantized Model: Accuracy = 0.8853, Precision = 0.8863, Time = 1.3744 seconds
"""

import numpy as np
from tensorflow import keras
import time
from sklearn.metrics import precision_score

def quantize_weights(weights, num_bits):
    """Quantize the weights to a specific number of bits."""
    min_val = np.min(weights)
    max_val = np.max(weights)

    # Calculate the scale and zero point
    scale = (max_val - min_val) / (2**num_bits - 1)
    zero_point = int(0.5 - min_val / scale)

    # Quantize the weights
    quantized_weights = np.round((weights - min_val) / scale) + zero_point

    # Dequantize the weights to get the approximate original values
    dequantized_weights = (quantized_weights - zero_point) * scale + min_val

    return dequantized_weights

# Load data
data = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = data.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images = train_images/255.0
test_images = test_images/255.0

# Ensure the test images are of type FLOAT32
test_images = test_images.astype(np.float32)

# Define model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(256, activation="relu"),
    keras.layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Train model
model.fit(train_images, train_labels, epochs=10)

# Quantize the weights of the first dense layer
weights, biases = model.layers[1].get_weights()
quantized_weights = quantize_weights(weights, num_bits=64) # Cant go to 128 bits
model.layers[1].set_weights([quantized_weights, biases])

# Evaluate the quantized model
start_time = time.time()
quantized_preds = model.predict(test_images)
quantized_time = time.time() - start_time
quantized_accuracy = np.mean(np.argmax(quantized_preds, axis=1) == test_labels)
quantized_precision = precision_score(test_labels, np.argmax(quantized_preds, axis=1), average='weighted')

# Print results
print(f"Quantized Model: Accuracy = {quantized_accuracy:.4f}, Precision = {quantized_precision:.4f}, Time = {quantized_time:.4f} seconds")

import numpy as np
from tensorflow import keras
import time
from sklearn.metrics import precision_score

def quantize_weights(weights, num_bits):
    """Quantize the weights to a specific number of bits."""
    min_val = np.min(weights)
    max_val = np.max(weights)

    # Calculate the scale and zero point
    scale = (max_val - min_val) / (2**num_bits - 1)
    zero_point = int(0.5 - min_val / scale)

    # Quantize the weights
    quantized_weights = np.round((weights - min_val) / scale) + zero_point

    # Dequantize the weights to get the approximate original values
    dequantized_weights = (quantized_weights - zero_point) * scale + min_val

    return dequantized_weights

# Load data
data = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = data.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images = train_images/255.0
test_images = test_images/255.0

# Ensure the test images are of type FLOAT32
test_images = test_images.astype(np.float32)

# Define model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(256, activation="relu"),
    keras.layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Train model
model.fit(train_images, train_labels, epochs=20)

# Quantize the weights of the first dense layer
weights, biases = model.layers[1].get_weights()
quantized_weights = quantize_weights(weights, num_bits=64) # Cant go to 128 bits
model.layers[1].set_weights([quantized_weights, biases])

# Evaluate the quantized model
start_time = time.time()
quantized_preds = model.predict(test_images)
quantized_time = time.time() - start_time
quantized_accuracy = np.mean(np.argmax(quantized_preds, axis=1) == test_labels)
quantized_precision = precision_score(test_labels, np.argmax(quantized_preds, axis=1), average='weighted')

# Print results
print(f"Quantized Model: Accuracy = {quantized_accuracy:.4f}, Precision = {quantized_precision:.4f}, Time = {quantized_time:.4f} seconds")